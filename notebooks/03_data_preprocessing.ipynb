{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c873100e",
   "metadata": {},
   "source": [
    "* NOTEBOOK: 03_data_preprocessing.ipynb\n",
    "* DESCRIPTION: Data Preprocessing Pipeline (Cleaning & Encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1ed5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95560878",
   "metadata": {},
   "source": [
    "# 1. LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a0b94f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../data/medical_insurance_data.csv')\n",
    "    print(\"Data Loaded Successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found! Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35ee5a",
   "metadata": {},
   "source": [
    "# 2. DATA CLEANING (Handling Missing Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d003d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Size: 2772 rows\n",
      "Cleaned Dataset Size:  2736 rows (Missing values removed)\n"
     ]
    }
   ],
   "source": [
    "# Removing rows with missing data to ensure high model accuracy.\n",
    "print(f\"Original Dataset Size: {df.shape[0]} rows\")\n",
    "df_clean = df.dropna().reset_index(drop=True)\n",
    "print(f\"Cleaned Dataset Size:  {df_clean.shape[0]} rows (Missing values removed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc845bd7",
   "metadata": {},
   "source": [
    "# 3. FEATURE ENCODING (Text to Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59028182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after Encoding (Ready for AI):\n",
      "   age  sex     bmi  children  smoker  region      charges\n",
      "0   19    1  27.900       0.0       0       1  16884.92400\n",
      "1   18    0  33.770       1.0       1       0   1725.55230\n",
      "2   28    0  33.000       3.0       1       0   4449.46200\n",
      "3   33    0  22.705       0.0       1       3  21984.47061\n",
      "4   32    0  28.880       0.0       1       3   3866.85520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHRIYUT\\AppData\\Local\\Temp\\ipykernel_8900\\3195520762.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean.replace({'sex': {'male': 0, 'female': 1}}, inplace=True)\n",
      "C:\\Users\\SHRIYUT\\AppData\\Local\\Temp\\ipykernel_8900\\3195520762.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean.replace({'smoker': {'yes': 0, 'no': 1}}, inplace=True)\n",
      "C:\\Users\\SHRIYUT\\AppData\\Local\\Temp\\ipykernel_8900\\3195520762.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean.replace({'region': {'southeast': 0, 'southwest': 1, 'northeast': 2, 'northwest': 3}}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# We use 'Manual Mapping' here to have full control over the values.\n",
    "# This ensures that specific categories are assigned specific numbers consistently.\n",
    "\n",
    "# Encoding 'sex' column\n",
    "# Mapping: male = 0, female = 1\n",
    "df_clean.replace({'sex': {'male': 0, 'female': 1}}, inplace=True)\n",
    "\n",
    "# Encoding 'smoker' column\n",
    "# Mapping: yes = 0, no = 1\n",
    "# (Note: We are assigning 0 to smokers and 1 to non-smokers)\n",
    "df_clean.replace({'smoker': {'yes': 0, 'no': 1}}, inplace=True)\n",
    "\n",
    "# Encoding 'region' column\n",
    "# Mapping regions to specific integer codes (0, 1, 2, 3)\n",
    "df_clean.replace({'region': {'southeast': 0, 'southwest': 1, 'northeast': 2, 'northwest': 3}}, inplace=True)\n",
    "\n",
    "print(\"\\nData after Encoding (Ready for AI):\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506cafe",
   "metadata": {},
   "source": [
    "# 4. DATA SPLITTING (Train vs Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "405db175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contains the Input Features (Age, BMI, Smoker, etc.)\n",
    "# y contains the Target Variable (Insurance Charges)\n",
    "X = df_clean.drop('charges', axis=1)\n",
    "y = df_clean['charges']\n",
    "\n",
    "# We split the data: 80% for Training the model, 20% for Testing performance.\n",
    "# random_state is fixed to ensure consistent results across the team.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024e707",
   "metadata": {},
   "source": [
    "# 5. SAVE PROCESSED DATA (Golden Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e0ae1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " PHASE 3 COMPLETE: Processed Data Saved Successfully.\n",
      "The 'X_train.csv' and 'X_test.csv' files are ready for model building.\n"
     ]
    }
   ],
   "source": [
    "# Saving the processed files so all team members use the same data for modeling.\n",
    "X_train.to_csv('../data/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/X_test.csv', index=False)\n",
    "y_train.to_csv('../data/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/y_test.csv', index=False)\n",
    "\n",
    "print(\"\\n PHASE 3 COMPLETE: Processed Data Saved Successfully.\")\n",
    "print(\"The 'X_train.csv' and 'X_test.csv' files are ready for model building.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a60f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036910c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
